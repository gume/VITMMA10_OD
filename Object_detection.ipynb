{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Közlekedési táblák - objektum felismerés.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "druPm4mQlp_L"
      },
      "source": [
        "# 1. Futtatási környezet telepítése\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3dRwjzRCpi2"
      },
      "source": [
        "A legtöbb itt található kód még mindig a TensorFlow 1.x környezethez készült, ezért kénytelenek vagyunk ezt használni. A futás során látszani fog, hogy az eljárások már elavultak. Erről még szerencsére jó eredményre fogunk jutni.\n",
        "\n",
        "Érdemes GPU futtatási környezetet választani, ugaynis a futás így sokszor gyorsabb lesz, mint CPU környezetben. A tanítás lefuthat pár tucat percen belül akár."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrMJt5qFknaU",
        "outputId": "12b6eac4-2864-4bc7-d3dd-1ab0f03bfedf"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIs326harKHG"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools tf_slim lvis\n",
        "\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/:/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPn3IzPY8Ora"
      },
      "source": [
        "## GTSDB\n",
        "\n",
        "A tanító képek a GTSDB adatbázisból is érkezhetnek. Itt már annotálva található többszáz kép. 43 különböző jelzőtáblát tartalmaznak. Az annotálás formája ugyanakkor nem jó közvetlenül ide, így először azt át kell alakítani. Az adatbázis a következő linken érhető el:\n",
        "\n",
        "https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "\n",
        "A képek ráadásul kisméretűek, így feltehetően csak rengeteg tanítással fognak működni.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWTehrhlJuN9"
      },
      "source": [
        "## Ez a repo tartalmazza a GTSDB-t, illetve egy egyszerűbb képgyűjteményt is annotálással."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWm5KZ0yUSnX"
      },
      "source": [
        "%cd /content\n",
        "! git clone https://github.com/gume/VITMMA10_OD.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inlzMMKUC82U"
      },
      "source": [
        "(opcionális) A következő sor csak akkor, ha a repo valamiért frissülne a futás közben."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYVoj5-EfJ--"
      },
      "source": [
        "%cd /content/VITMMA10_OD\n",
        "! git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yII-O8P7l5n4"
      },
      "source": [
        "## Tanító szet előállítása a képekből\n",
        "\n",
        "A tanításra tfrecord fájlokat használunk, amelyek tartalmazzák az összes képet és annotálást is. Két ilyen recordra van szükségünk, az egyik a tanításhoz (train), a másik az ellenőrzéshez (test). A tanulás közben a train képeken végzett tanulás vissz van ellenőrizve a test képekkel.\n",
        "\n",
        "A képek mellett már xml formában megtalálható az annotálás. Új képek esetén az labelImg program segítségével készíthető annotálás.\n",
        "https://github.com/tzutalin/labelImg\n",
        "\n",
        "Az átalakítás után előáll egy címke fájl is, amiben a képeken szereplő címkék vannak.\n",
        "\n",
        "A record fáljok megörzik a tartalmukat a művelet során. Véletlen újrafuttatás esetén így duplán lesz benne minden. Ezt elkerülendő érdemes először a fájlokat letörölni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7qgoHufCE_Q"
      },
      "source": [
        "images_path = '/content/VITMMA10_OD/VITMMA10/images/stop'\n",
        "tfrecord_path = '/content/'\n",
        "\n",
        "# Generating these files\n",
        "images_csv = os.path.join(tfrecord_path, 'vitmma10_stop.csv')\n",
        "images_train_csv = os.path.join(tfrecord_path, 'vitmma10_stop_train.csv')\n",
        "images_test_csv = os.path.join(tfrecord_path, 'vitmma10_stop_test.csv')\n",
        "\n",
        "train_record_fname = os.path.join(tfrecord_path, 'train.tfrecord')\n",
        "test_record_fname = os.path.join(tfrecord_path, 'test.tfrecord')\n",
        "label_map_pbtxt_fname = os.path.join(tfrecord_path, 'map.pbtxt')\n",
        "\n",
        "!python /content/VITMMA10_OD/code/generate_csv.py xml {images_path} {images_csv}\n",
        "!python /content/VITMMA10_OD/code/generate_pbtxt.py csv {images_csv} {label_map_pbtxt_fname}\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "image_df = pd.read_csv(images_csv)\n",
        "train_files, test_files = train_test_split(image_df.filename.unique(), test_size=0.2)\n",
        "train_df = pd.DataFrame()\n",
        "test_df = pd.DataFrame()\n",
        "for i, row in image_df.iterrows():\n",
        "  if row.filename in test_files:\n",
        "    test_df = test_df.append(row)\n",
        "  else:\n",
        "    train_df = train_df.append(row)\n",
        "train_df.to_csv(images_train_csv)\n",
        "test_df.to_csv(images_test_csv)\n",
        "\n",
        "!python /content/VITMMA10_OD/code/generate_tfrecord.py {images_train_csv} {label_map_pbtxt_fname} {images_path} {train_record_fname}\n",
        "!python /content/VITMMA10_OD/code/generate_tfrecord.py {images_test_csv} {label_map_pbtxt_fname} {images_path} {test_record_fname}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YgnN3xaIM3v"
      },
      "source": [
        "### TFrecord tesztelése\n",
        "\n",
        "Csak, ha valami formai hiba lenne vele. A képeket meg is lehet jeleníteni, ebben az esetben le kell tölteni a recordokat és egy külön kód meg tudja jeleníteni.\n",
        "\n",
        "Én ezt a toolt találtam hasznosnak (bár a kód elején érdemes az tensorflow modult tensorflow.compat.v1 -re cserélni). Ez a tool itt a colabon viszont nem futtatható.\n",
        "https://github.com/sulc/tfrecord-viewer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8B5V5HIIMjO"
      },
      "source": [
        "import glob\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "total_images = 0\n",
        "train_files = sorted(glob.glob(os.path.join(tfrecord_path, '*.tfrecord')))\n",
        "for idx, file in enumerate(train_files):\n",
        "  try:\n",
        "    total_images += sum([1 for _ in tf.io.tf_record_iterator(file)]) # Check corrupted tf records\n",
        "  except Exception as e:\n",
        "    print(\"{}: {} is corrupted. {}\".format(idx, file, e))\n",
        "print(\"Succeed, no corrupted tf records found for {} images\".format(total_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCkRJ38w3gpr"
      },
      "source": [
        "# 2. Modell kiválasztása és telepítése\n",
        "\n",
        "Több modell közül is lehet választani. A modellekről itt lehet bővebb információt találni:\n",
        "https://github.com/tensorflow/models/tree/master/research/object_detection/g3doc\n",
        "\n",
        "Itt kerül meghatározásra az is, hogy hány lépésből álljon a tanítás. Kis számok esetán (pl. 1000) is lehet már eredményt látni, de a jobb működés érdekében érdemes nagy számmit választani és megvárni a hosszabb tanítást."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXSbAZVYraA_"
      },
      "source": [
        "# Number of training steps.  # 200000\n",
        "num_steps = 2000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_inception_v2': {\n",
        "        'model_name': 'ssd_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'ssd_inception_v2_coco.config',\n",
        "        'batch_size': 8\n",
        "    },\n",
        "    'ssd_mobilenet_v2_quantized': {\n",
        "        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobilenet_v1_fpn': {\n",
        "        'model_name': 'ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03',\n",
        "        'pipeline_file': 'ssd_mobilenet_v1_fpn_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobilenet_v1': {\n",
        "        'model_name': 'ssd_mobilenet_v1_coco_2018_01_28',\n",
        "        'pipeline_file': 'ssd_mobilenet_v1_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_coco.config',\n",
        "        'batch_size': 1\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_coco.config',\n",
        "        'batch_size': 8\n",
        "    },\n",
        "    'faster_rfcn_resnet101': {\n",
        "        'model_name': 'faster_rcnn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rfcn_resnet101_coco.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'faster_rcnn_inception_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZdn5rgf3Hao"
      },
      "source": [
        "\n",
        "## Model letöltése\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbC0GWWDQKmV"
      },
      "source": [
        "! rm -rf /content/models/research/pretrained_model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVXhdIQU3Hut"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHSlZC6Q4_SM"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_eXi5bplbT3"
      },
      "source": [
        "## Konfigurációs fájl készítése\n",
        "\n",
        "A modell felépítése egy konfigurációs fájlban található. A modellel együtt elérhető az eredeti konfiguráció is, amit csak pár helyen elegendő módosítani. Az alábbi kód elvégzi a szükséges módosításokat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15S-6Zab5EFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f831b39-a5c5-4131-99e7-048c95355b9e"
      },
      "source": [
        "DEST_DIR = \"/content/models/research/pretrained_model\"\n",
        "!cp /content/models/research/object_detection/samples/configs/{pipeline_file} {DEST_DIR}\n",
        "\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "print(fine_tune_checkpoint)\n",
        "print(pipeline_file)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model/model.ckpt\n",
            "faster_rcnn_inception_v2_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNTMqOHE6BAW"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "pipeline_fname_original = os.path.join(DEST_DIR, pipeline_file)\n",
        "pipeline_fname = os.path.join(DEST_DIR, \"pipeline.config\")\n",
        "assert os.path.isfile(pipeline_fname_original), '`{}` not exist'.format(pipeline_fname_original)\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname_original) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9sfVLSDfAIQ"
      },
      "source": [
        "Néhány konfigurációs fájl javításra szorulhat. Google keresés segíthet a problémákon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgWaP-G1_l0w"
      },
      "source": [
        "# 3. Tanítás"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VlG2rMy_YZ4"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuB7Ir-TN1Ci"
      },
      "source": [
        "A tensorboard segítségével figyelemmel kísérhető a tanítás állapota. Itt colab-ban inkább csak egy egy futtatás után látjuk, hogy mi történt. A image tabnál egész jól használható információt kapunk a tanítás állapotáról. A képeknél a bal oldalon látjuk, hogy működik e a felismerés, ha nincs ott bekeretezve semmi, akkor bizony nem működik. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlQ_wVp8CIpZ"
      },
      "source": [
        "%reload_ext tensorboard"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDVZiYa7CLrG"
      },
      "source": [
        "%cd /content\n",
        "%tensorboard --logdir 'training/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQywvkho_SXF"
      },
      "source": [
        "(opcionális) A figyelmeztető üzenetek kikapcsolása"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4HFWm8w_a1W"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AZA6Ex0BEJp"
      },
      "source": [
        "## A konkrét tanítás"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy36Owus00M1"
      },
      "source": [
        "pipeline_fname = os.path.join(DEST_DIR, \"pipeline.config\")\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYm-mV8-Cwz4"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDLn8_2xPjA8"
      },
      "source": [
        "Az alábbi kód egy régebbi módszer a tanításhoz. Elegendő a fenti kód használata erre nincs szükség"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkUuzJsysrZK"
      },
      "source": [
        "# !python /content/models/research/object_detection/legacy/train.py \\\n",
        "#    --logtostderr \\\n",
        "#    --train_dir={model_dir} \\\n",
        "#    --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdNaoGBSRdDn"
      },
      "source": [
        "# 4. Modell konvertálása és elmentése\n",
        "\n",
        "Amikor már elégedettek vagyunk az eredménnyel, a modellt használható állapotban kell elmenteni. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCRWm5AwuWJv"
      },
      "source": [
        "!rm -rf '/content/fine_tuned_model'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6PMelYHRzaX"
      },
      "source": [
        "Ez a konfiguráció csak tesztelés jellegel. Az eredeti modellre vonatkozik, így azt a modellt lehet elmenteni, amiből a tanítás kiindult."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSr-ExUXnNih"
      },
      "source": [
        "# output_directory = '/content/fine_tuned_model'\n",
        "# pipeline_fname = '/content/models/research/pretrained_model/pipeline.config.original'\n",
        "# last_model_path = '/content/models/research/pretrained_model/model.ckpt'\n",
        "# saved_model_path = '/content/models/research/pretrained_model/saved_model'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PLQKoUgQGur"
      },
      "source": [
        "Megkeresi a legutolsó tanítási állapotot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq"
      },
      "source": [
        "output_directory = '/content/fine_tuned_model'\n",
        "pipeline_fname = '/content/models/research/pretrained_model/pipeline.config'\n",
        "saved_model_path = ''\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnP3_HG9-T6i"
      },
      "source": [
        "pipeline_fname='/content/models/research/pretrained_model/pipeline.config'"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J3RcAECQNnL"
      },
      "source": [
        "A modell exportálása, ezt a fájl tudjuk majd később használni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wE71_gN5RQZ"
      },
      "source": [
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ2hEZ_gQYUA"
      },
      "source": [
        "## Innentől az átalakítás csak opcionális, különböző formátumokbe lehet konvertálni. Bizonyos környezetekben előnyös lehet egyik másik."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLvQB3tqTkcE"
      },
      "source": [
        "### Átalakítás tflife fromátumba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj59rsDz1-nG"
      },
      "source": [
        "!echo \"CONVERTING saved model to TF Lite file...\"\n",
        "!tflite_convert \\\n",
        "  --output_file='{output_directory}/model.tflite' \\\n",
        "  --saved_model_dir='{saved_model_path}' \\\n",
        "  --enable_v1_converter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R6U7Wp7Cpnz"
      },
      "source": [
        "!echo \"CONVERTING saved model to TF Lite file...\"\n",
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "    --pipeline_config_path {pipeline_fname} \\\n",
        "    --trained_checkpoint_prefix {last_model_path} \\\n",
        "    --output_directory {output_directory}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY6kNZwNTrfX"
      },
      "source": [
        "### Átalakítás ONNX fromátumba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzX9P_OdYav1"
      },
      "source": [
        "!pip install tf2onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLU8wNb0YxG0"
      },
      "source": [
        "saved_model_path = '/content/fine_tuned_model/saved_model'\n",
        "\n",
        "!python -m tf2onnx.convert \\\n",
        " --saved-model {saved_model_path} \\\n",
        " --output {output_directory}/frozen_inference_graph.onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQM6wXhaG9J8"
      },
      "source": [
        "!python -m tf2onnx.convert \\\n",
        "  --input {frozen_inference_graph} \\\n",
        "  --inputs 'image_tensor:0[1,300,300,3]' \\\n",
        "  --outputs 'detection_boxes:0,detection_scores:0,num_detections:0,detection_classes:0' \\\n",
        "  --opset 11 --fold_const \\\n",
        "  --output {output_directory}/frozen_inference_graph.onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBdz0Z1bHqjG"
      },
      "source": [
        "output_directory = '/content/fine_tuned_model'\n",
        "pipeline_fname = '/content/fine_tuned_model/pipeline.config'\n",
        "last_model_path = '/content/fine_tuned_model/model.ckpt'\n",
        "saved_model_path = '/content/fine_tuned_model/saved_model'\n",
        "frozen_inference_graph = '/content/fine_tuned_model/frozen_inference_graph.pb'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6WbjOFbKqaM"
      },
      "source": [
        "!pip install onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4eBsoPnT1zd"
      },
      "source": [
        "ONNX formátum tesztelése"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtb4sWAaKflC"
      },
      "source": [
        " import onnx\n",
        "\n",
        " # Checks \n",
        " onnx_model = onnx.load('/content/fine_tuned_model/frozen_inference_graph.onnx')  # load onnx model \n",
        " onnx.checker.check_model(onnx_model)  # check onnx model \n",
        " print(onnx.helper.printable_graph(onnx_model.graph))  # print a human readable representation of the graph \n",
        " print('ONNX export success, saved as %s\\nView with https://github.com/lutzroeder/netron' % f) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RdBpi3CUjBg"
      },
      "source": [
        "## Modell letöltése\n",
        "\n",
        "Attól függően milyen formátumba konvertáltuk, különböző fájlokat lehet letölteni. Aalap esetben a következő két fájlra lesz szükség:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP0iMMnnr77"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1TbL6Ox8q6Z"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRr3OtYGWu87"
      },
      "source": [
        "# 5. Használat\n",
        "\n",
        "A használat során újabb képekkel tesztelünk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ5CUFXmUsO6"
      },
      "source": [
        "## Tesztelés TensorFlowval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/content/fine_tuned_model/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "#PATH_TO_TEST_IMAGES_DIR =  '/content/VITMMA10_OD/data/images/test' # os.path.join(repo_dir_path, \"test\")\n",
        "#\n",
        "#assert os.path.isfile(pb_fname)\n",
        "#assert os.path.isfile(PATH_TO_LABELS)\n",
        "#TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg\"))\n",
        "#assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "#print(TEST_IMAGE_PATHS)\n",
        "TEST_IMAGE_PATHS = ['/content/VITMMA10_OD/googlemaps/street1z.jpg']\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    print(output_dict)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxjKuLP4U0zc"
      },
      "source": [
        "## Tesztelés OPENCVvel\n",
        "\n",
        "A futás sikere sokmindentől függ. A modell, a verziószámok, ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nCLWvjKKSaE"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/opencv/opencv.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGj0whnpLB1d"
      },
      "source": [
        "frozen_inference_graph = '/content/fine_tuned_model/frozen_inference_graph.pb'\n",
        "pipeline_fname = '/content/fine_tuned_model/pipeline.config'\n",
        "opencv_pbtxt_fname = '/content/fine_tuned_model/opencv.pbtxt'\n",
        "\n",
        "!python /content/opencv/samples/dnn/tf_text_graph_faster_rcnn.py --input {frozen_inference_graph} --config {pipeline_fname} --output {opencv_pbtxt_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGn2APd7p4hc"
      },
      "source": [
        "# How to load a Tensorflow model using OpenCV\n",
        "# Jean Vitor de Paulo Blog - https://jeanvitor.com/tensorflow-object-detecion-opencv/\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Load a model imported from Tensorflow\n",
        "tensorflowNet = cv2.dnn.readNetFromTensorflow(frozen_inference_graph, opencv_pbtxt_fname)\n",
        "#tensorflowNet = cv2.dnn.readNetFromONNX('/content/fine_tuned_model/frozen_inference_graph_test.onnx')\n",
        "\n",
        "# Input image\n",
        "img = cv2.imread('/content/VITMMA10_OD/googlemaps/street1z.jpg')\n",
        "rows, cols, channels = img.shape\n",
        "\n",
        "# Use the given image as input, which needs to be blob(s).\n",
        "tensorflowNet.setInput(cv2.dnn.blobFromImage(img, size=(300, 300), swapRB=True, crop=False))\n",
        "\n",
        "# Runs a forward pass to compute the net output\n",
        "networkOutput = tensorflowNet.forward()\n",
        "\n",
        "# Loop on the outputs\n",
        "for detection in networkOutput[0,0]:\n",
        "    \n",
        "    score = float(detection[2])\n",
        "    if score > 0.2:\n",
        "    \t\n",
        "        left = detection[3] * cols\n",
        "        top = detection[4] * rows\n",
        "        right = detection[5] * cols\n",
        "        bottom = detection[6] * rows\n",
        "\n",
        "        #draw a red rectangle around detected objects\n",
        "        cv2.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), (0, 0, 255), thickness=2)\n",
        "\n",
        "# Show the image with a rectagle surrounding the detected objects \n",
        "cv2.imshow('Image', img)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}