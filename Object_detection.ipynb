{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Közlekedési táblák - objektum felismerés.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "druPm4mQlp_L"
      },
      "source": [
        "# 1. Futtatási környezet telepítése\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3dRwjzRCpi2"
      },
      "source": [
        "A legtöbb itt található kód még mindig a TensorFlow 1.x környezethez készült, ezért kénytelenek vagyunk ezt használni. A futás során látszani fog, hogy az eljárások már elavultak. Erről még szerencsére jó eredményre fogunk jutni.\n",
        "\n",
        "Érdemes GPU futtatási környezetet választani, ugaynis a futás így sokszor gyorsabb lesz, mint CPU környezetben. A tanítás lefuthat pár tucat percen belül akár."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrMJt5qFknaU",
        "outputId": "b7cd1287-dab1-4f59-b26e-90abf96d5622"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIs326harKHG"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools tf_slim lvis\n",
        "\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/:/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPn3IzPY8Ora"
      },
      "source": [
        "## GTSDB\n",
        "\n",
        "A tanító képek a GTSDB adatbázisból is érkezhetnek. Itt már annotálva található többszáz kép. 43 különböző jelzőtáblát tartalmaznak. Az annotálás formája ugyanakkor nem jó közvetlenül ide, így először azt át kell alakítani. Az adatbázis a következő linken érhető el:\n",
        "\n",
        "https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "\n",
        "A képek ráadásul kisméretűek, így feltehetően csak rengeteg tanítással fognak működni.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWTehrhlJuN9"
      },
      "source": [
        "## Ez a repo tartalmazza a GTSDB-t, illetve egy egyszerűbb képgyűjteményt is annotálással."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWm5KZ0yUSnX",
        "outputId": "24495aef-09ad-431c-f609-b64cedda2ec1"
      },
      "source": [
        "%cd /content\n",
        "! git clone https://github.com/gume/VITMMA10_OD.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'VITMMA10_OD'...\n",
            "remote: Enumerating objects: 200, done.\u001b[K\n",
            "remote: Counting objects: 100% (200/200), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 1324 (delta 119), reused 198 (delta 118), pack-reused 1124\u001b[K\n",
            "Receiving objects: 100% (1324/1324), 337.28 MiB | 20.64 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n",
            "Checking out files: 100% (1247/1247), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inlzMMKUC82U"
      },
      "source": [
        "(opcionális) A következő sor csak akkor, ha a repo valamiért frissülne a futás közben."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYVoj5-EfJ--"
      },
      "source": [
        "%cd /content/VITMMA10_OD\n",
        "! git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yII-O8P7l5n4"
      },
      "source": [
        "## Tanító szet előállítása a képekből\n",
        "\n",
        "A tanításra tfrecord fájlokat használunk, amelyek tartalmazzák az összes képet és annotálást is. Két ilyen recordra van szükségünk, az egyik a tanításhoz (train), a másik az ellenőrzéshez (test). A tanulás közben a train képeken végzett tanulás vissz van ellenőrizve a test képekkel.\n",
        "\n",
        "A képek mellett már xml formában megtalálható az annotálás. Új képek esetén az labelImg program segítségével készíthető annotálás.\n",
        "https://github.com/tzutalin/labelImg\n",
        "\n",
        "Az átalakítás után előáll egy címke fájl is, amiben a képeken szereplő címkék vannak.\n",
        "\n",
        "A record fáljok megörzik a tartalmukat a művelet során. Véletlen újrafuttatás esetén így duplán lesz benne minden. Ezt elkerülendő érdemes először a fájlokat letörölni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7qgoHufCE_Q",
        "outputId": "72e7aaf2-5563-41c3-e3b3-00f5d3d8b69e"
      },
      "source": [
        "images_path = '/content/VITMMA10_OD/VITMMA10/images/stop'\n",
        "tfrecord_path = '/content/'\n",
        "\n",
        "# Generating these files\n",
        "images_csv = os.path.join(tfrecord_path, 'vitmma10_stop.csv')\n",
        "images_train_csv = os.path.join(tfrecord_path, 'vitmma10_stop_train.csv')\n",
        "images_test_csv = os.path.join(tfrecord_path, 'vitmma10_stop_test.csv')\n",
        "\n",
        "train_record_fname = os.path.join(tfrecord_path, 'train.tfrecord')\n",
        "test_record_fname = os.path.join(tfrecord_path, 'test.tfrecord')\n",
        "label_map_pbtxt_fname = os.path.join(tfrecord_path, 'map.pbtxt')\n",
        "\n",
        "!python /content/VITMMA10_OD/code/generate_csv.py xml {images_path} {images_csv}\n",
        "!python /content/VITMMA10_OD/code/generate_pbtxt.py csv {images_csv} {label_map_pbtxt_fname}\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "image_df = pd.read_csv(images_csv)\n",
        "train_files, test_files = train_test_split(image_df.filename.unique(), test_size=0.2)\n",
        "train_df = pd.DataFrame()\n",
        "test_df = pd.DataFrame()\n",
        "for i, row in image_df.iterrows():\n",
        "  if row.filename in test_files:\n",
        "    test_df = test_df.append(row)\n",
        "  else:\n",
        "    train_df = train_df.append(row)\n",
        "train_df.to_csv(images_train_csv)\n",
        "test_df.to_csv(images_test_csv)\n",
        "\n",
        "!python /content/VITMMA10_OD/code/generate_tfrecord.py {images_train_csv} {label_map_pbtxt_fname} {images_path} {train_record_fname}\n",
        "!python /content/VITMMA10_OD/code/generate_tfrecord.py {images_test_csv} {label_map_pbtxt_fname} {images_path} {test_record_fname}\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 74/74 [00:00<00:00, 21910.10it/s]\n",
            "groups: 100% 59/59 [00:00<00:00, 783.71it/s]\n",
            "Successfully created the TFRecords: /content/train.tfrecord\n",
            "groups: 100% 15/15 [00:00<00:00, 781.45it/s]\n",
            "Successfully created the TFRecords: /content/test.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YgnN3xaIM3v"
      },
      "source": [
        "### TFrecord tesztelése\n",
        "\n",
        "Csak, ha valami formai hiba lenne vele. A képeket meg is lehet jeleníteni, ebben az esetben le kell tölteni a recordokat és egy külön kód meg tudja jeleníteni.\n",
        "\n",
        "Én ezt a toolt találtam hasznosnak (bár a kód elején érdemes az tensorflow modult tensorflow.compat.v1 -re cserélni). Ez a tool itt a colabon viszont nem futtatható.\n",
        "https://github.com/sulc/tfrecord-viewer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8B5V5HIIMjO"
      },
      "source": [
        "import glob\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "total_images = 0\n",
        "train_files = sorted(glob.glob(os.path.join(tfrecord_path, '*.tfrecord')))\n",
        "for idx, file in enumerate(train_files):\n",
        "  try:\n",
        "    total_images += sum([1 for _ in tf.io.tf_record_iterator(file)]) # Check corrupted tf records\n",
        "  except Exception as e:\n",
        "    print(\"{}: {} is corrupted. {}\".format(idx, file, e))\n",
        "print(\"Succeed, no corrupted tf records found for {} images\".format(total_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCkRJ38w3gpr"
      },
      "source": [
        "# 2. Modell kiválasztása és telepítése\n",
        "\n",
        "Több modell közül is lehet választani. A modellekről itt lehet bővebb információt találni:\n",
        "https://github.com/tensorflow/models/tree/master/research/object_detection/g3doc\n",
        "\n",
        "Itt kerül meghatározásra az is, hogy hány lépésből álljon a tanítás. Kis számok esetán (pl. 1000) is lehet már eredményt látni, de a jobb működés érdekében érdemes nagy számmit választani és megvárni a hosszabb tanítást."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXSbAZVYraA_"
      },
      "source": [
        "# Number of training steps.  # 200000\n",
        "num_steps = 20000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_inception_v2': {\n",
        "        'model_name': 'ssd_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'ssd_inception_v2_coco.config',\n",
        "        'batch_size': 8\n",
        "    },\n",
        "    'ssd_mobilenet_v2_quantized': {\n",
        "        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobilenet_v1_fpn': {\n",
        "        'model_name': 'ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03',\n",
        "        'pipeline_file': 'ssd_mobilenet_v1_fpn_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobilenet_v1': {\n",
        "        'model_name': 'ssd_mobilenet_v1_coco_2018_01_28',\n",
        "        'pipeline_file': 'ssd_mobilenet_v1_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_coco.config',\n",
        "        'batch_size': 1\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_coco.config',\n",
        "        'batch_size': 8\n",
        "    },\n",
        "    'faster_rfcn_resnet101': {\n",
        "        'model_name': 'faster_rcnn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rfcn_resnet101_coco.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'faster_rcnn_inception_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZdn5rgf3Hao"
      },
      "source": [
        "\n",
        "## Model letöltése\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbC0GWWDQKmV"
      },
      "source": [
        "! rm -rf /content/models/research/pretrained_model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVXhdIQU3Hut",
        "outputId": "97ce7b5a-3147-4ba7-e996-ce6cb81dcc87"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHSlZC6Q4_SM",
        "outputId": "257aff74-e455-4dec-fa81-9938c159de2a"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 111M\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
            "drwxr-xr-x 24 root   root 4.0K Nov 28 11:09 ..\n",
            "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
            "-rw-r--r--  1 345018 5000  55M Feb  1  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 5000  51M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 5000  16K Feb  1  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 5000 5.5M Feb  1  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 5000 3.2K Feb  1  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_eXi5bplbT3"
      },
      "source": [
        "## Konfigurációs fájl készítése\n",
        "\n",
        "A modell felépítése egy konfigurációs fájlban található. A modellel együtt elérhető az eredeti konfiguráció is, amit csak pár helyen elegendő módosítani. Az alábbi kód elvégzi a szükséges módosításokat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15S-6Zab5EFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaed3cb8-80e4-40c8-c7f6-cc30c1d67a6b"
      },
      "source": [
        "DEST_DIR = \"/content/models/research/pretrained_model\"\n",
        "!cp /content/models/research/object_detection/samples/configs/{pipeline_file} {DEST_DIR}\n",
        "\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "print(fine_tune_checkpoint)\n",
        "print(pipeline_file)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model/model.ckpt\n",
            "faster_rcnn_inception_v2_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNTMqOHE6BAW"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "pipeline_fname_original = os.path.join(DEST_DIR, pipeline_file)\n",
        "pipeline_fname = os.path.join(DEST_DIR, \"pipeline.config\")\n",
        "assert os.path.isfile(pipeline_fname_original), '`{}` not exist'.format(pipeline_fname_original)\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname_original) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9sfVLSDfAIQ"
      },
      "source": [
        "Néhány konfigurációs fájl javításra szorulhat. Google keresés segíthet a problémákon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgWaP-G1_l0w"
      },
      "source": [
        "# 3. Tanítás"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VlG2rMy_YZ4",
        "outputId": "d7635028-49f8-437d-ee39-2c96ad3bb7da"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuB7Ir-TN1Ci"
      },
      "source": [
        "A tensorboard segítségével figyelemmel kísérhető a tanítás állapota. Itt colab-ban inkább csak egy egy futtatás után látjuk, hogy mi történt. A image tabnál egész jól használható információt kapunk a tanítás állapotáról. A képeknél a bal oldalon látjuk, hogy működik e a felismerés, ha nincs ott bekeretezve semmi, akkor bizony nem működik. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlQ_wVp8CIpZ"
      },
      "source": [
        "%reload_ext tensorboard"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDVZiYa7CLrG"
      },
      "source": [
        "%cd /content\n",
        "%tensorboard --logdir 'training/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQywvkho_SXF"
      },
      "source": [
        "(opcionális) A figyelmeztető üzenetek kikapcsolása"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4HFWm8w_a1W"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AZA6Ex0BEJp"
      },
      "source": [
        "## A konkrét tanítás"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy36Owus00M1",
        "outputId": "0903b7c7-43b1-44b2-dffd-bcbd2feb859d"
      },
      "source": [
        "pipeline_fname = os.path.join(DEST_DIR, \"pipeline.config\")\n",
        "%cd /content"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYm-mV8-Cwz4",
        "outputId": "597998cf-49ac-47f9-a4e3-aa3ec356bf38"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1128 11:36:59.259374 140319373666176 model_lib.py:793] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 20000\n",
            "I1128 11:36:59.259686 140319373666176 config_util.py:552] Maybe overwriting train_steps: 20000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1128 11:36:59.259785 140319373666176 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I1128 11:36:59.259863 140319373666176 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1128 11:36:59.259962 140319373666176 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1128 11:36:59.260066 140319373666176 model_lib.py:809] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I1128 11:36:59.260154 140319373666176 model_lib.py:846] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9e321346a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I1128 11:36:59.260541 140319373666176 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9e321346a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f9e32138950>) includes params argument, but params are not passed to Estimator.\n",
            "W1128 11:36:59.260783 140319373666176 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f9e32138950>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I1128 11:36:59.261576 140319373666176 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I1128 11:36:59.261777 140319373666176 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I1128 11:36:59.261999 140319373666176 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W1128 11:36:59.269637 140319373666176 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/train.tfrecord']\n",
            "I1128 11:36:59.298566 140319373666176 dataset_builder.py:148] Reading unweighted datasets: ['/content/train.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/train.tfrecord']\n",
            "I1128 11:36:59.299700 140319373666176 dataset_builder.py:77] Reading record datasets for input file: ['/content/train.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1128 11:36:59.299825 140319373666176 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1128 11:36:59.299902 140319373666176 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W1128 11:36:59.304869 140319373666176 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1128 11:36:59.323787 140319373666176 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9e3009a828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1128 11:36:59.355364 140319373666176 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9e3009a828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f9e32138c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1128 11:36:59.524098 140319373666176 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f9e32138c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1128 11:36:59.525274 140319373666176 deprecation.py:323] From /content/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:96: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1128 11:36:59.532178 140319373666176 deprecation.py:323] From /content/models/research/object_detection/inputs.py:96: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:283: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1128 11:36:59.653502 140319373666176 deprecation.py:323] From /content/models/research/object_detection/inputs.py:283: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1128 11:37:00.015188 140319373666176 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1128 11:37:00.045073 140319373666176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:37:01.336494 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:37:01.463852 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1128 11:37:01.464261 140319373666176 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W1128 11:37:02.150661 140319373666176 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W1128 11:37:02.612198 140319373666176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:37:02.614312 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:37:02.628877 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W1128 11:37:02.892133 140319373666176 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1128 11:37:06.370213 140319373666176 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I1128 11:37:06.371471 140319373666176 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1128 11:37:08.006787 140319373666176 monitored_session.py:240] Graph was finalized.\n",
            "2020-11-28 11:37:08.011522: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-11-28 11:37:08.011788: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xe264a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-28 11:37:08.011822: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-11-28 11:37:08.013686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-11-28 11:37:08.120312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:37:08.121017: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xe264840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-28 11:37:08.121061: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-11-28 11:37:08.121276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:37:08.121809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-11-28 11:37:08.122175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-28 11:37:08.123771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-28 11:37:08.125692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-28 11:37:08.126036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-28 11:37:08.127610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-28 11:37:08.128357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-28 11:37:08.131495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-28 11:37:08.131646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:37:08.132233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:37:08.132733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-11-28 11:37:08.132797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-28 11:37:08.133996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-11-28 11:37:08.134021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-11-28 11:37:08.134044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-11-28 11:37:08.134157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:37:08.134720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:37:08.135222: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-11-28 11:37:08.135261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I1128 11:37:08.137681 140319373666176 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W1128 11:37:09.026869 140319373666176 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1128 11:37:09.594384 140319373666176 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1128 11:37:09.745839 140319373666176 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into training/model.ckpt.\n",
            "I1128 11:37:14.535541 140319373666176 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into training/model.ckpt.\n",
            "2020-11-28 11:37:18.648772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-28 11:37:19.331450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 0.12683387, step = 10000\n",
            "I1128 11:37:21.633363 140319373666176 basic_session_run_hooks.py:262] loss = 0.12683387, step = 10000\n",
            "INFO:tensorflow:global_step/sec: 3.27233\n",
            "I1128 11:37:52.191769 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 3.27233\n",
            "INFO:tensorflow:loss = 0.10669847, step = 10100 (30.559 sec)\n",
            "I1128 11:37:52.192724 140319373666176 basic_session_run_hooks.py:260] loss = 0.10669847, step = 10100 (30.559 sec)\n",
            "INFO:tensorflow:global_step/sec: 7.982\n",
            "I1128 11:38:04.719940 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 7.982\n",
            "INFO:tensorflow:loss = 0.09732945, step = 10200 (12.528 sec)\n",
            "I1128 11:38:04.720892 140319373666176 basic_session_run_hooks.py:260] loss = 0.09732945, step = 10200 (12.528 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.24293\n",
            "I1128 11:38:15.539021 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.24293\n",
            "INFO:tensorflow:loss = 0.25758585, step = 10300 (10.819 sec)\n",
            "I1128 11:38:15.540199 140319373666176 basic_session_run_hooks.py:260] loss = 0.25758585, step = 10300 (10.819 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.59592\n",
            "I1128 11:38:25.960113 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.59592\n",
            "INFO:tensorflow:loss = 0.07648072, step = 10400 (10.421 sec)\n",
            "I1128 11:38:25.961195 140319373666176 basic_session_run_hooks.py:260] loss = 0.07648072, step = 10400 (10.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.60067\n",
            "I1128 11:38:36.376053 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.60067\n",
            "INFO:tensorflow:loss = 0.06840001, step = 10500 (10.416 sec)\n",
            "I1128 11:38:36.377211 140319373666176 basic_session_run_hooks.py:260] loss = 0.06840001, step = 10500 (10.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.59314\n",
            "I1128 11:38:46.800185 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.59314\n",
            "INFO:tensorflow:loss = 0.17051086, step = 10600 (10.424 sec)\n",
            "I1128 11:38:46.801277 140319373666176 basic_session_run_hooks.py:260] loss = 0.17051086, step = 10600 (10.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.53089\n",
            "I1128 11:38:57.292385 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.53089\n",
            "INFO:tensorflow:loss = 0.2682351, step = 10700 (10.493 sec)\n",
            "I1128 11:38:57.293888 140319373666176 basic_session_run_hooks.py:260] loss = 0.2682351, step = 10700 (10.493 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.49798\n",
            "I1128 11:39:07.820935 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.49798\n",
            "INFO:tensorflow:loss = 0.13167468, step = 10800 (10.528 sec)\n",
            "I1128 11:39:07.821881 140319373666176 basic_session_run_hooks.py:260] loss = 0.13167468, step = 10800 (10.528 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.5551\n",
            "I1128 11:39:18.286544 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.5551\n",
            "INFO:tensorflow:loss = 0.261772, step = 10900 (10.466 sec)\n",
            "I1128 11:39:18.287575 140319373666176 basic_session_run_hooks.py:260] loss = 0.261772, step = 10900 (10.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.60638\n",
            "I1128 11:39:28.696291 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.60638\n",
            "INFO:tensorflow:loss = 0.11257706, step = 11000 (10.410 sec)\n",
            "I1128 11:39:28.697223 140319373666176 basic_session_run_hooks.py:260] loss = 0.11257706, step = 11000 (10.410 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.56186\n",
            "I1128 11:39:39.154531 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.56186\n",
            "INFO:tensorflow:loss = 0.09493056, step = 11100 (10.458 sec)\n",
            "I1128 11:39:39.155583 140319373666176 basic_session_run_hooks.py:260] loss = 0.09493056, step = 11100 (10.458 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.51635\n",
            "I1128 11:39:49.662750 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.51635\n",
            "INFO:tensorflow:loss = 0.0855769, step = 11200 (10.508 sec)\n",
            "I1128 11:39:49.663892 140319373666176 basic_session_run_hooks.py:260] loss = 0.0855769, step = 11200 (10.508 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.55432\n",
            "I1128 11:40:00.129222 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.55432\n",
            "INFO:tensorflow:loss = 0.27864268, step = 11300 (10.466 sec)\n",
            "I1128 11:40:00.130376 140319373666176 basic_session_run_hooks.py:260] loss = 0.27864268, step = 11300 (10.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.55934\n",
            "I1128 11:40:10.590171 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.55934\n",
            "INFO:tensorflow:loss = 0.09624681, step = 11400 (10.461 sec)\n",
            "I1128 11:40:10.591235 140319373666176 basic_session_run_hooks.py:260] loss = 0.09624681, step = 11400 (10.461 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.48985\n",
            "I1128 11:40:21.127764 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.48985\n",
            "INFO:tensorflow:loss = 1.0951393, step = 11500 (10.538 sec)\n",
            "I1128 11:40:21.128861 140319373666176 basic_session_run_hooks.py:260] loss = 1.0951393, step = 11500 (10.538 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.61535\n",
            "I1128 11:40:31.527801 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.61535\n",
            "INFO:tensorflow:loss = 0.08707012, step = 11600 (10.400 sec)\n",
            "I1128 11:40:31.528935 140319373666176 basic_session_run_hooks.py:260] loss = 0.08707012, step = 11600 (10.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.6615\n",
            "I1128 11:40:41.878154 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.6615\n",
            "INFO:tensorflow:loss = 0.17098075, step = 11700 (10.350 sec)\n",
            "I1128 11:40:41.879310 140319373666176 basic_session_run_hooks.py:260] loss = 0.17098075, step = 11700 (10.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.5759\n",
            "I1128 11:40:52.321019 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.5759\n",
            "INFO:tensorflow:loss = 0.21572886, step = 11800 (10.443 sec)\n",
            "I1128 11:40:52.321871 140319373666176 basic_session_run_hooks.py:260] loss = 0.21572886, step = 11800 (10.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.6113\n",
            "I1128 11:41:02.725439 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.6113\n",
            "INFO:tensorflow:loss = 0.09905839, step = 11900 (10.405 sec)\n",
            "I1128 11:41:02.726376 140319373666176 basic_session_run_hooks.py:260] loss = 0.09905839, step = 11900 (10.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58181\n",
            "I1128 11:41:13.161902 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58181\n",
            "INFO:tensorflow:loss = 0.11463766, step = 12000 (10.437 sec)\n",
            "I1128 11:41:13.163018 140319373666176 basic_session_run_hooks.py:260] loss = 0.11463766, step = 12000 (10.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.52998\n",
            "I1128 11:41:23.655102 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.52998\n",
            "INFO:tensorflow:loss = 0.06456725, step = 12100 (10.493 sec)\n",
            "I1128 11:41:23.656184 140319373666176 basic_session_run_hooks.py:260] loss = 0.06456725, step = 12100 (10.493 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58551\n",
            "I1128 11:41:34.087510 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58551\n",
            "INFO:tensorflow:loss = 0.087131575, step = 12200 (10.432 sec)\n",
            "I1128 11:41:34.088431 140319373666176 basic_session_run_hooks.py:260] loss = 0.087131575, step = 12200 (10.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.59591\n",
            "I1128 11:41:44.508635 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.59591\n",
            "INFO:tensorflow:loss = 0.14673758, step = 12300 (10.421 sec)\n",
            "I1128 11:41:44.509730 140319373666176 basic_session_run_hooks.py:260] loss = 0.14673758, step = 12300 (10.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.54839\n",
            "I1128 11:41:54.981610 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.54839\n",
            "INFO:tensorflow:loss = 0.10951714, step = 12400 (10.473 sec)\n",
            "I1128 11:41:54.982460 140319373666176 basic_session_run_hooks.py:260] loss = 0.10951714, step = 12400 (10.473 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.48143\n",
            "I1128 11:42:05.528519 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.48143\n",
            "INFO:tensorflow:loss = 0.24781278, step = 12500 (10.547 sec)\n",
            "I1128 11:42:05.529633 140319373666176 basic_session_run_hooks.py:260] loss = 0.24781278, step = 12500 (10.547 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.67666\n",
            "I1128 11:42:15.862699 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.67666\n",
            "INFO:tensorflow:loss = 0.74746215, step = 12600 (10.334 sec)\n",
            "I1128 11:42:15.863866 140319373666176 basic_session_run_hooks.py:260] loss = 0.74746215, step = 12600 (10.334 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.54498\n",
            "I1128 11:42:26.339407 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.54498\n",
            "INFO:tensorflow:loss = 0.045505412, step = 12700 (10.477 sec)\n",
            "I1128 11:42:26.340855 140319373666176 basic_session_run_hooks.py:260] loss = 0.045505412, step = 12700 (10.477 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.57774\n",
            "I1128 11:42:36.780256 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.57774\n",
            "INFO:tensorflow:loss = 0.057634447, step = 12800 (10.440 sec)\n",
            "I1128 11:42:36.781146 140319373666176 basic_session_run_hooks.py:260] loss = 0.057634447, step = 12800 (10.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58522\n",
            "I1128 11:42:47.212976 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58522\n",
            "INFO:tensorflow:loss = 0.07310873, step = 12900 (10.433 sec)\n",
            "I1128 11:42:47.214200 140319373666176 basic_session_run_hooks.py:260] loss = 0.07310873, step = 12900 (10.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.55395\n",
            "I1128 11:42:57.679858 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.55395\n",
            "INFO:tensorflow:loss = 0.028279424, step = 13000 (10.467 sec)\n",
            "I1128 11:42:57.680762 140319373666176 basic_session_run_hooks.py:260] loss = 0.028279424, step = 13000 (10.467 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.60707\n",
            "I1128 11:43:08.088851 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.60707\n",
            "INFO:tensorflow:loss = 0.8374496, step = 13100 (10.409 sec)\n",
            "I1128 11:43:08.089843 140319373666176 basic_session_run_hooks.py:260] loss = 0.8374496, step = 13100 (10.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.51419\n",
            "I1128 11:43:18.599463 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.51419\n",
            "INFO:tensorflow:loss = 0.067699626, step = 13200 (10.511 sec)\n",
            "I1128 11:43:18.600667 140319373666176 basic_session_run_hooks.py:260] loss = 0.067699626, step = 13200 (10.511 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.5958\n",
            "I1128 11:43:29.020721 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.5958\n",
            "INFO:tensorflow:loss = 0.20911172, step = 13300 (10.421 sec)\n",
            "I1128 11:43:29.021858 140319373666176 basic_session_run_hooks.py:260] loss = 0.20911172, step = 13300 (10.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.56844\n",
            "I1128 11:43:39.471729 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.56844\n",
            "INFO:tensorflow:loss = 0.23876663, step = 13400 (10.451 sec)\n",
            "I1128 11:43:39.472890 140319373666176 basic_session_run_hooks.py:260] loss = 0.23876663, step = 13400 (10.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.55756\n",
            "I1128 11:43:49.934652 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.55756\n",
            "INFO:tensorflow:loss = 0.1337717, step = 13500 (10.463 sec)\n",
            "I1128 11:43:49.935864 140319373666176 basic_session_run_hooks.py:260] loss = 0.1337717, step = 13500 (10.463 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.46557\n",
            "I1128 11:44:00.499232 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.46557\n",
            "INFO:tensorflow:loss = 0.08320348, step = 13600 (10.564 sec)\n",
            "I1128 11:44:00.500298 140319373666176 basic_session_run_hooks.py:260] loss = 0.08320348, step = 13600 (10.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.48393\n",
            "I1128 11:44:11.043377 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.48393\n",
            "INFO:tensorflow:loss = 0.031242311, step = 13700 (10.544 sec)\n",
            "I1128 11:44:11.044234 140319373666176 basic_session_run_hooks.py:260] loss = 0.031242311, step = 13700 (10.544 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.5077\n",
            "I1128 11:44:21.561179 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.5077\n",
            "INFO:tensorflow:loss = 0.13597317, step = 13800 (10.518 sec)\n",
            "I1128 11:44:21.562134 140319373666176 basic_session_run_hooks.py:260] loss = 0.13597317, step = 13800 (10.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.5276\n",
            "I1128 11:44:32.057011 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.5276\n",
            "INFO:tensorflow:loss = 0.056113206, step = 13900 (10.496 sec)\n",
            "I1128 11:44:32.058064 140319373666176 basic_session_run_hooks.py:260] loss = 0.056113206, step = 13900 (10.496 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.56742\n",
            "I1128 11:44:42.509134 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.56742\n",
            "INFO:tensorflow:loss = 0.20437644, step = 14000 (10.452 sec)\n",
            "I1128 11:44:42.509977 140319373666176 basic_session_run_hooks.py:260] loss = 0.20437644, step = 14000 (10.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58273\n",
            "I1128 11:44:52.944600 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58273\n",
            "INFO:tensorflow:loss = 0.5943938, step = 14100 (10.436 sec)\n",
            "I1128 11:44:52.945680 140319373666176 basic_session_run_hooks.py:260] loss = 0.5943938, step = 14100 (10.436 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.50504\n",
            "I1128 11:45:03.465311 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.50504\n",
            "INFO:tensorflow:loss = 0.028665176, step = 14200 (10.521 sec)\n",
            "I1128 11:45:03.466451 140319373666176 basic_session_run_hooks.py:260] loss = 0.028665176, step = 14200 (10.521 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.51884\n",
            "I1128 11:45:13.970798 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.51884\n",
            "INFO:tensorflow:loss = 0.079209924, step = 14300 (10.506 sec)\n",
            "I1128 11:45:13.972118 140319373666176 basic_session_run_hooks.py:260] loss = 0.079209924, step = 14300 (10.506 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.49886\n",
            "I1128 11:45:24.498358 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.49886\n",
            "INFO:tensorflow:loss = 0.04606323, step = 14400 (10.527 sec)\n",
            "I1128 11:45:24.499520 140319373666176 basic_session_run_hooks.py:260] loss = 0.04606323, step = 14400 (10.527 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.53205\n",
            "I1128 11:45:34.989297 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.53205\n",
            "INFO:tensorflow:loss = 0.07798209, step = 14500 (10.491 sec)\n",
            "I1128 11:45:34.990489 140319373666176 basic_session_run_hooks.py:260] loss = 0.07798209, step = 14500 (10.491 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.62165\n",
            "I1128 11:45:45.382509 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.62165\n",
            "INFO:tensorflow:loss = 0.038347393, step = 14600 (10.393 sec)\n",
            "I1128 11:45:45.383531 140319373666176 basic_session_run_hooks.py:260] loss = 0.038347393, step = 14600 (10.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.54262\n",
            "I1128 11:45:55.861830 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.54262\n",
            "INFO:tensorflow:loss = 0.0520752, step = 14700 (10.479 sec)\n",
            "I1128 11:45:55.862803 140319373666176 basic_session_run_hooks.py:260] loss = 0.0520752, step = 14700 (10.479 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.60464\n",
            "I1128 11:46:06.273462 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.60464\n",
            "INFO:tensorflow:loss = 0.048140265, step = 14800 (10.412 sec)\n",
            "I1128 11:46:06.274531 140319373666176 basic_session_run_hooks.py:260] loss = 0.048140265, step = 14800 (10.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.53291\n",
            "I1128 11:46:16.763442 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.53291\n",
            "INFO:tensorflow:loss = 0.10305203, step = 14900 (10.490 sec)\n",
            "I1128 11:46:16.764439 140319373666176 basic_session_run_hooks.py:260] loss = 0.10305203, step = 14900 (10.490 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.59403\n",
            "I1128 11:46:27.186590 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.59403\n",
            "INFO:tensorflow:loss = 0.37587565, step = 15000 (10.423 sec)\n",
            "I1128 11:46:27.187790 140319373666176 basic_session_run_hooks.py:260] loss = 0.37587565, step = 15000 (10.423 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.63813\n",
            "I1128 11:46:37.562043 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.63813\n",
            "INFO:tensorflow:loss = 0.14020033, step = 15100 (10.375 sec)\n",
            "I1128 11:46:37.562847 140319373666176 basic_session_run_hooks.py:260] loss = 0.14020033, step = 15100 (10.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.57522\n",
            "I1128 11:46:48.005696 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.57522\n",
            "INFO:tensorflow:loss = 0.10983185, step = 15200 (10.444 sec)\n",
            "I1128 11:46:48.006790 140319373666176 basic_session_run_hooks.py:260] loss = 0.10983185, step = 15200 (10.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.54004\n",
            "I1128 11:46:58.487786 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.54004\n",
            "INFO:tensorflow:loss = 0.08618515, step = 15300 (10.482 sec)\n",
            "I1128 11:46:58.488858 140319373666176 basic_session_run_hooks.py:260] loss = 0.08618515, step = 15300 (10.482 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.61833\n",
            "I1128 11:47:08.884618 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.61833\n",
            "INFO:tensorflow:loss = 0.051164545, step = 15400 (10.397 sec)\n",
            "I1128 11:47:08.885739 140319373666176 basic_session_run_hooks.py:260] loss = 0.051164545, step = 15400 (10.397 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 15467 into training/model.ckpt.\n",
            "I1128 11:47:15.779180 140319373666176 basic_session_run_hooks.py:606] Saving checkpoints for 15467 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/test.tfrecord']\n",
            "I1128 11:47:16.616902 140319373666176 dataset_builder.py:148] Reading unweighted datasets: ['/content/test.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/test.tfrecord']\n",
            "I1128 11:47:16.617963 140319373666176 dataset_builder.py:77] Reading record datasets for input file: ['/content/test.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1128 11:47:16.618118 140319373666176 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9e203ccc50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1128 11:47:16.660437 140319373666176 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9e203ccc50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f9e2d4c2d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1128 11:47:16.824397 140319373666176 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f9e2d4c2d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1128 11:47:17.353073 140319373666176 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:47:18.572348 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:47:18.698458 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1128 11:47:18.698868 140319373666176 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:47:19.769854 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:47:19.784584 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1128 11:47:20.622386 140319373666176 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W1128 11:47:20.799976 140319373666176 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1128 11:47:21.313944 140319373666176 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-11-28T11:47:21Z\n",
            "I1128 11:47:21.329214 140319373666176 evaluation.py:255] Starting evaluation at 2020-11-28T11:47:21Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1128 11:47:21.744208 140319373666176 monitored_session.py:240] Graph was finalized.\n",
            "2020-11-28 11:47:21.745296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:47:21.745740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-11-28 11:47:21.745872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-28 11:47:21.745903: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-28 11:47:21.745926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-28 11:47:21.745949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-28 11:47:21.745969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-28 11:47:21.745990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-28 11:47:21.746012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-28 11:47:21.746098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:47:21.746506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:47:21.746855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-11-28 11:47:21.746899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-11-28 11:47:21.746912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-11-28 11:47:21.746922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-11-28 11:47:21.747010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:47:21.747401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:47:21.747766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-15467\n",
            "I1128 11:47:21.748695 140319373666176 saver.py:1284] Restoring parameters from training/model.ckpt-15467\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1128 11:47:22.731888 140319373666176 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1128 11:47:22.879482 140319373666176 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 15 images.\n",
            "I1128 11:47:27.953241 140317130909440 coco_evaluation.py:293] Performing evaluation on 15 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1128 11:47:27.953701 140317130909440 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1128 11:47:27.954662 140317130909440 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.882\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.835\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.713\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.713\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767\n",
            "INFO:tensorflow:Finished evaluation at 2020-11-28-11:47:29\n",
            "I1128 11:47:29.586663 140319373666176 evaluation.py:275] Finished evaluation at 2020-11-28-11:47:29\n",
            "INFO:tensorflow:Saving dict for global step 15467: DetectionBoxes_Precision/mAP = 0.64158535, DetectionBoxes_Precision/mAP (large) = 0.73494846, DetectionBoxes_Precision/mAP (medium) = 0.2669871, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8824429, DetectionBoxes_Precision/mAP@.75IOU = 0.8352628, DetectionBoxes_Recall/AR@1 = 0.7, DetectionBoxes_Recall/AR@10 = 0.7133333, DetectionBoxes_Recall/AR@100 = 0.7133333, DetectionBoxes_Recall/AR@100 (large) = 0.76666665, DetectionBoxes_Recall/AR@100 (medium) = 0.5, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.059977856, Loss/BoxClassifierLoss/localization_loss = 0.038158115, Loss/RPNLoss/localization_loss = 0.20021954, Loss/RPNLoss/objectness_loss = 0.29989675, Loss/total_loss = 0.59825224, global_step = 15467, learning_rate = 0.0002, loss = 0.59825224\n",
            "I1128 11:47:29.586983 140319373666176 estimator.py:2049] Saving dict for global step 15467: DetectionBoxes_Precision/mAP = 0.64158535, DetectionBoxes_Precision/mAP (large) = 0.73494846, DetectionBoxes_Precision/mAP (medium) = 0.2669871, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8824429, DetectionBoxes_Precision/mAP@.75IOU = 0.8352628, DetectionBoxes_Recall/AR@1 = 0.7, DetectionBoxes_Recall/AR@10 = 0.7133333, DetectionBoxes_Recall/AR@100 = 0.7133333, DetectionBoxes_Recall/AR@100 (large) = 0.76666665, DetectionBoxes_Recall/AR@100 (medium) = 0.5, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.059977856, Loss/BoxClassifierLoss/localization_loss = 0.038158115, Loss/RPNLoss/localization_loss = 0.20021954, Loss/RPNLoss/objectness_loss = 0.29989675, Loss/total_loss = 0.59825224, global_step = 15467, learning_rate = 0.0002, loss = 0.59825224\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15467: training/model.ckpt-15467\n",
            "I1128 11:47:30.388724 140319373666176 estimator.py:2109] Saving 'checkpoint_path' summary for global step 15467: training/model.ckpt-15467\n",
            "INFO:tensorflow:global_step/sec: 3.99633\n",
            "I1128 11:47:33.907605 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 3.99633\n",
            "INFO:tensorflow:loss = 0.059289746, step = 15500 (25.023 sec)\n",
            "I1128 11:47:33.908466 140319373666176 basic_session_run_hooks.py:260] loss = 0.059289746, step = 15500 (25.023 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.59536\n",
            "I1128 11:47:44.329295 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.59536\n",
            "INFO:tensorflow:loss = 0.052400265, step = 15600 (10.422 sec)\n",
            "I1128 11:47:44.330247 140319373666176 basic_session_run_hooks.py:260] loss = 0.052400265, step = 15600 (10.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.46435\n",
            "I1128 11:47:54.895269 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.46435\n",
            "INFO:tensorflow:loss = 0.028531304, step = 15700 (10.566 sec)\n",
            "I1128 11:47:54.896465 140319373666176 basic_session_run_hooks.py:260] loss = 0.028531304, step = 15700 (10.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.51364\n",
            "I1128 11:48:05.406495 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.51364\n",
            "INFO:tensorflow:loss = 0.07086452, step = 15800 (10.511 sec)\n",
            "I1128 11:48:05.407763 140319373666176 basic_session_run_hooks.py:260] loss = 0.07086452, step = 15800 (10.511 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58685\n",
            "I1128 11:48:15.837447 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58685\n",
            "INFO:tensorflow:loss = 0.022083355, step = 15900 (10.431 sec)\n",
            "I1128 11:48:15.838598 140319373666176 basic_session_run_hooks.py:260] loss = 0.022083355, step = 15900 (10.431 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.5456\n",
            "I1128 11:48:26.313453 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.5456\n",
            "INFO:tensorflow:loss = 0.21277878, step = 16000 (10.476 sec)\n",
            "I1128 11:48:26.314405 140319373666176 basic_session_run_hooks.py:260] loss = 0.21277878, step = 16000 (10.476 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.53495\n",
            "I1128 11:48:36.801189 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.53495\n",
            "INFO:tensorflow:loss = 0.10285926, step = 16100 (10.488 sec)\n",
            "I1128 11:48:36.802262 140319373666176 basic_session_run_hooks.py:260] loss = 0.10285926, step = 16100 (10.488 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58202\n",
            "I1128 11:48:47.237396 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58202\n",
            "INFO:tensorflow:loss = 0.20564377, step = 16200 (10.436 sec)\n",
            "I1128 11:48:47.238389 140319373666176 basic_session_run_hooks.py:260] loss = 0.20564377, step = 16200 (10.436 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58447\n",
            "I1128 11:48:57.670954 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58447\n",
            "INFO:tensorflow:loss = 0.096692875, step = 16300 (10.434 sec)\n",
            "I1128 11:48:57.671976 140319373666176 basic_session_run_hooks.py:260] loss = 0.096692875, step = 16300 (10.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.60137\n",
            "I1128 11:49:08.086166 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.60137\n",
            "INFO:tensorflow:loss = 0.68855846, step = 16400 (10.415 sec)\n",
            "I1128 11:49:08.087351 140319373666176 basic_session_run_hooks.py:260] loss = 0.68855846, step = 16400 (10.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.55928\n",
            "I1128 11:49:18.547182 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.55928\n",
            "INFO:tensorflow:loss = 0.12164307, step = 16500 (10.461 sec)\n",
            "I1128 11:49:18.548209 140319373666176 basic_session_run_hooks.py:260] loss = 0.12164307, step = 16500 (10.461 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.46632\n",
            "I1128 11:49:29.110949 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.46632\n",
            "INFO:tensorflow:loss = 0.1059268, step = 16600 (10.564 sec)\n",
            "I1128 11:49:29.111885 140319373666176 basic_session_run_hooks.py:260] loss = 0.1059268, step = 16600 (10.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.60878\n",
            "I1128 11:49:39.518073 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.60878\n",
            "INFO:tensorflow:loss = 0.017866425, step = 16700 (10.407 sec)\n",
            "I1128 11:49:39.519007 140319373666176 basic_session_run_hooks.py:260] loss = 0.017866425, step = 16700 (10.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.60699\n",
            "I1128 11:49:49.927169 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.60699\n",
            "INFO:tensorflow:loss = 0.05213662, step = 16800 (10.409 sec)\n",
            "I1128 11:49:49.928072 140319373666176 basic_session_run_hooks.py:260] loss = 0.05213662, step = 16800 (10.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.54893\n",
            "I1128 11:50:00.399586 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.54893\n",
            "INFO:tensorflow:loss = 0.05029156, step = 16900 (10.473 sec)\n",
            "I1128 11:50:00.400834 140319373666176 basic_session_run_hooks.py:260] loss = 0.05029156, step = 16900 (10.473 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.57304\n",
            "I1128 11:50:10.845581 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.57304\n",
            "INFO:tensorflow:loss = 0.11390962, step = 17000 (10.446 sec)\n",
            "I1128 11:50:10.846695 140319373666176 basic_session_run_hooks.py:260] loss = 0.11390962, step = 17000 (10.446 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.52935\n",
            "I1128 11:50:21.339463 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.52935\n",
            "INFO:tensorflow:loss = 0.20995225, step = 17100 (10.494 sec)\n",
            "I1128 11:50:21.340588 140319373666176 basic_session_run_hooks.py:260] loss = 0.20995225, step = 17100 (10.494 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.57953\n",
            "I1128 11:50:31.778388 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.57953\n",
            "INFO:tensorflow:loss = 0.043752097, step = 17200 (10.439 sec)\n",
            "I1128 11:50:31.779265 140319373666176 basic_session_run_hooks.py:260] loss = 0.043752097, step = 17200 (10.439 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.63208\n",
            "I1128 11:50:42.160351 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.63208\n",
            "INFO:tensorflow:loss = 0.114522286, step = 17300 (10.382 sec)\n",
            "I1128 11:50:42.161360 140319373666176 basic_session_run_hooks.py:260] loss = 0.114522286, step = 17300 (10.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.63477\n",
            "I1128 11:50:52.539417 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.63477\n",
            "INFO:tensorflow:loss = 0.32177952, step = 17400 (10.379 sec)\n",
            "I1128 11:50:52.540520 140319373666176 basic_session_run_hooks.py:260] loss = 0.32177952, step = 17400 (10.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.61046\n",
            "I1128 11:51:02.944769 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.61046\n",
            "INFO:tensorflow:loss = 0.06699689, step = 17500 (10.405 sec)\n",
            "I1128 11:51:02.945839 140319373666176 basic_session_run_hooks.py:260] loss = 0.06699689, step = 17500 (10.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.56476\n",
            "I1128 11:51:13.399805 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.56476\n",
            "INFO:tensorflow:loss = 0.22395805, step = 17600 (10.455 sec)\n",
            "I1128 11:51:13.400986 140319373666176 basic_session_run_hooks.py:260] loss = 0.22395805, step = 17600 (10.455 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.56408\n",
            "I1128 11:51:23.855603 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.56408\n",
            "INFO:tensorflow:loss = 0.07465603, step = 17700 (10.456 sec)\n",
            "I1128 11:51:23.856578 140319373666176 basic_session_run_hooks.py:260] loss = 0.07465603, step = 17700 (10.456 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.63302\n",
            "I1128 11:51:34.236579 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.63302\n",
            "INFO:tensorflow:loss = 0.033549845, step = 17800 (10.381 sec)\n",
            "I1128 11:51:34.238047 140319373666176 basic_session_run_hooks.py:260] loss = 0.033549845, step = 17800 (10.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58856\n",
            "I1128 11:51:44.665676 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58856\n",
            "INFO:tensorflow:loss = 0.072122455, step = 17900 (10.429 sec)\n",
            "I1128 11:51:44.666953 140319373666176 basic_session_run_hooks.py:260] loss = 0.072122455, step = 17900 (10.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58751\n",
            "I1128 11:51:55.095896 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58751\n",
            "INFO:tensorflow:loss = 0.04388614, step = 18000 (10.430 sec)\n",
            "I1128 11:51:55.096787 140319373666176 basic_session_run_hooks.py:260] loss = 0.04388614, step = 18000 (10.430 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.59581\n",
            "I1128 11:52:05.517086 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.59581\n",
            "INFO:tensorflow:loss = 0.08877395, step = 18100 (10.421 sec)\n",
            "I1128 11:52:05.518151 140319373666176 basic_session_run_hooks.py:260] loss = 0.08877395, step = 18100 (10.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.6463\n",
            "I1128 11:52:15.883806 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.6463\n",
            "INFO:tensorflow:loss = 0.07843822, step = 18200 (10.367 sec)\n",
            "I1128 11:52:15.884790 140319373666176 basic_session_run_hooks.py:260] loss = 0.07843822, step = 18200 (10.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.66682\n",
            "I1128 11:52:26.228440 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.66682\n",
            "INFO:tensorflow:loss = 0.102620885, step = 18300 (10.345 sec)\n",
            "I1128 11:52:26.229617 140319373666176 basic_session_run_hooks.py:260] loss = 0.102620885, step = 18300 (10.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.55838\n",
            "I1128 11:52:36.690459 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.55838\n",
            "INFO:tensorflow:loss = 0.05952796, step = 18400 (10.462 sec)\n",
            "I1128 11:52:36.691541 140319373666176 basic_session_run_hooks.py:260] loss = 0.05952796, step = 18400 (10.462 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.55578\n",
            "I1128 11:52:47.155349 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.55578\n",
            "INFO:tensorflow:loss = 0.12301853, step = 18500 (10.465 sec)\n",
            "I1128 11:52:47.156577 140319373666176 basic_session_run_hooks.py:260] loss = 0.12301853, step = 18500 (10.465 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.56395\n",
            "I1128 11:52:57.611248 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.56395\n",
            "INFO:tensorflow:loss = 0.025488308, step = 18600 (10.456 sec)\n",
            "I1128 11:52:57.612321 140319373666176 basic_session_run_hooks.py:260] loss = 0.025488308, step = 18600 (10.456 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.50453\n",
            "I1128 11:53:08.132543 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.50453\n",
            "INFO:tensorflow:loss = 0.1916586, step = 18700 (10.521 sec)\n",
            "I1128 11:53:08.133708 140319373666176 basic_session_run_hooks.py:260] loss = 0.1916586, step = 18700 (10.521 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.44019\n",
            "I1128 11:53:18.725574 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.44019\n",
            "INFO:tensorflow:loss = 0.14903776, step = 18800 (10.593 sec)\n",
            "I1128 11:53:18.726685 140319373666176 basic_session_run_hooks.py:260] loss = 0.14903776, step = 18800 (10.593 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.60817\n",
            "I1128 11:53:29.133476 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.60817\n",
            "INFO:tensorflow:loss = 0.027097657, step = 18900 (10.408 sec)\n",
            "I1128 11:53:29.134604 140319373666176 basic_session_run_hooks.py:260] loss = 0.027097657, step = 18900 (10.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.55466\n",
            "I1128 11:53:39.599452 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.55466\n",
            "INFO:tensorflow:loss = 0.060435344, step = 19000 (10.466 sec)\n",
            "I1128 11:53:39.600489 140319373666176 basic_session_run_hooks.py:260] loss = 0.060435344, step = 19000 (10.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58142\n",
            "I1128 11:53:50.036393 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58142\n",
            "INFO:tensorflow:loss = 0.05380545, step = 19100 (10.437 sec)\n",
            "I1128 11:53:50.037860 140319373666176 basic_session_run_hooks.py:260] loss = 0.05380545, step = 19100 (10.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.59995\n",
            "I1128 11:54:00.453089 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.59995\n",
            "INFO:tensorflow:loss = 0.1063917, step = 19200 (10.416 sec)\n",
            "I1128 11:54:00.454085 140319373666176 basic_session_run_hooks.py:260] loss = 0.1063917, step = 19200 (10.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.65209\n",
            "I1128 11:54:10.813502 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.65209\n",
            "INFO:tensorflow:loss = 0.035473283, step = 19300 (10.361 sec)\n",
            "I1128 11:54:10.814665 140319373666176 basic_session_run_hooks.py:260] loss = 0.035473283, step = 19300 (10.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.64665\n",
            "I1128 11:54:21.179802 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.64665\n",
            "INFO:tensorflow:loss = 0.06080185, step = 19400 (10.366 sec)\n",
            "I1128 11:54:21.180784 140319373666176 basic_session_run_hooks.py:260] loss = 0.06080185, step = 19400 (10.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.58204\n",
            "I1128 11:54:31.616000 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.58204\n",
            "INFO:tensorflow:loss = 0.13376392, step = 19500 (10.436 sec)\n",
            "I1128 11:54:31.616966 140319373666176 basic_session_run_hooks.py:260] loss = 0.13376392, step = 19500 (10.436 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.48284\n",
            "I1128 11:54:42.161354 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.48284\n",
            "INFO:tensorflow:loss = 0.12790804, step = 19600 (10.545 sec)\n",
            "I1128 11:54:42.162369 140319373666176 basic_session_run_hooks.py:260] loss = 0.12790804, step = 19600 (10.545 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.59032\n",
            "I1128 11:54:52.588526 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.59032\n",
            "INFO:tensorflow:loss = 0.03331506, step = 19700 (10.427 sec)\n",
            "I1128 11:54:52.589344 140319373666176 basic_session_run_hooks.py:260] loss = 0.03331506, step = 19700 (10.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.60512\n",
            "I1128 11:55:02.999689 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.60512\n",
            "INFO:tensorflow:loss = 0.06940428, step = 19800 (10.411 sec)\n",
            "I1128 11:55:03.000841 140319373666176 basic_session_run_hooks.py:260] loss = 0.06940428, step = 19800 (10.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.57325\n",
            "I1128 11:55:13.445401 140319373666176 basic_session_run_hooks.py:692] global_step/sec: 9.57325\n",
            "INFO:tensorflow:loss = 0.14709646, step = 19900 (10.446 sec)\n",
            "I1128 11:55:13.446471 140319373666176 basic_session_run_hooks.py:260] loss = 0.14709646, step = 19900 (10.446 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into training/model.ckpt.\n",
            "I1128 11:55:23.784511 140319373666176 basic_session_run_hooks.py:606] Saving checkpoints for 20000 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W1128 11:55:23.903342 140319373666176 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I1128 11:55:24.545645 140319373666176 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/test.tfrecord']\n",
            "I1128 11:55:24.563376 140319373666176 dataset_builder.py:148] Reading unweighted datasets: ['/content/test.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/test.tfrecord']\n",
            "I1128 11:55:24.564742 140319373666176 dataset_builder.py:77] Reading record datasets for input file: ['/content/test.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1128 11:55:24.564892 140319373666176 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9db8a057b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1128 11:55:24.602913 140319373666176 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9db8a057b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f9b7fda0f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1128 11:55:24.767798 140319373666176 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f9b7fda0f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1128 11:55:25.300416 140319373666176 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:55:26.757360 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:55:26.889795 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1128 11:55:26.890191 140319373666176 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:55:27.786649 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:55:27.801134 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1128 11:55:29.277906 140319373666176 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-11-28T11:55:29Z\n",
            "I1128 11:55:29.292838 140319373666176 evaluation.py:255] Starting evaluation at 2020-11-28T11:55:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1128 11:55:29.705813 140319373666176 monitored_session.py:240] Graph was finalized.\n",
            "2020-11-28 11:55:29.706492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:29.706948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-11-28 11:55:29.707106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-28 11:55:29.707134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-28 11:55:29.707164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-28 11:55:29.707197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-28 11:55:29.707229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-28 11:55:29.707254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-28 11:55:29.707285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-28 11:55:29.707382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:29.707790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:29.708114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-11-28 11:55:29.708166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-11-28 11:55:29.708183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-11-28 11:55:29.708192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-11-28 11:55:29.708283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:29.708673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:29.709040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-20000\n",
            "I1128 11:55:29.710156 140319373666176 saver.py:1284] Restoring parameters from training/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1128 11:55:30.703268 140319373666176 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1128 11:55:30.843348 140319373666176 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 15 images.\n",
            "I1128 11:55:34.251333 140317130909440 coco_evaluation.py:293] Performing evaluation on 15 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1128 11:55:34.252636 140317130909440 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1128 11:55:34.253740 140317130909440 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.896\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.754\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.704\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.673\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.687\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
            "INFO:tensorflow:Finished evaluation at 2020-11-28-11:55:35\n",
            "I1128 11:55:35.856635 140319373666176 evaluation.py:275] Finished evaluation at 2020-11-28-11:55:35\n",
            "INFO:tensorflow:Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.6173848, DetectionBoxes_Precision/mAP (large) = 0.7040429, DetectionBoxes_Precision/mAP (medium) = 0.17837882, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8962184, DetectionBoxes_Precision/mAP@.75IOU = 0.75436807, DetectionBoxes_Recall/AR@1 = 0.67333335, DetectionBoxes_Recall/AR@10 = 0.68666667, DetectionBoxes_Recall/AR@100 = 0.68666667, DetectionBoxes_Recall/AR@100 (large) = 0.7416667, DetectionBoxes_Recall/AR@100 (medium) = 0.46666667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.057141066, Loss/BoxClassifierLoss/localization_loss = 0.034268994, Loss/RPNLoss/localization_loss = 0.21131058, Loss/RPNLoss/objectness_loss = 0.32660922, Loss/total_loss = 0.6293298, global_step = 20000, learning_rate = 0.0002, loss = 0.6293298\n",
            "I1128 11:55:35.856932 140319373666176 estimator.py:2049] Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.6173848, DetectionBoxes_Precision/mAP (large) = 0.7040429, DetectionBoxes_Precision/mAP (medium) = 0.17837882, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8962184, DetectionBoxes_Precision/mAP@.75IOU = 0.75436807, DetectionBoxes_Recall/AR@1 = 0.67333335, DetectionBoxes_Recall/AR@10 = 0.68666667, DetectionBoxes_Recall/AR@100 = 0.68666667, DetectionBoxes_Recall/AR@100 (large) = 0.7416667, DetectionBoxes_Recall/AR@100 (medium) = 0.46666667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.057141066, Loss/BoxClassifierLoss/localization_loss = 0.034268994, Loss/RPNLoss/localization_loss = 0.21131058, Loss/RPNLoss/objectness_loss = 0.32660922, Loss/total_loss = 0.6293298, global_step = 20000, learning_rate = 0.0002, loss = 0.6293298\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: training/model.ckpt-20000\n",
            "I1128 11:55:35.864780 140319373666176 estimator.py:2109] Saving 'checkpoint_path' summary for global step 20000: training/model.ckpt-20000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I1128 11:55:35.865568 140319373666176 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1128 11:55:36.134517 140319373666176 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:55:37.333330 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:55:37.459712 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1128 11:55:37.460095 140319373666176 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:55:38.591822 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1128 11:55:38.606459 140319373666176 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1128 11:55:39.224648 140319373666176 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W1128 11:55:39.224951 140319373666176 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I1128 11:55:39.225589 140319373666176 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I1128 11:55:39.225713 140319373666176 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I1128 11:55:39.225793 140319373666176 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I1128 11:55:39.225862 140319373666176 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I1128 11:55:39.225926 140319373666176 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2020-11-28 11:55:39.226481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:39.226929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-11-28 11:55:39.227019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-28 11:55:39.227046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-28 11:55:39.227065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-28 11:55:39.227087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-28 11:55:39.227107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-28 11:55:39.227127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-28 11:55:39.227148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-28 11:55:39.227240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:39.227660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:39.227999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-11-28 11:55:39.228039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-11-28 11:55:39.228053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-11-28 11:55:39.228062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-11-28 11:55:39.228152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:39.228537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-28 11:55:39.228923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-20000\n",
            "I1128 11:55:39.231171 140319373666176 saver.py:1284] Restoring parameters from training/model.ckpt-20000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I1128 11:55:39.748434 140319373666176 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I1128 11:55:39.748678 140319373666176 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1606564535'/saved_model.pb\n",
            "I1128 11:55:40.563812 140319373666176 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1606564535'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.15011695.\n",
            "I1128 11:55:40.759608 140319373666176 estimator.py:371] Loss for final step: 0.15011695.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDLn8_2xPjA8"
      },
      "source": [
        "Az alábbi kód egy régebbi módszer a tanításhoz. Elegendő a fenti kód használata erre nincs szükség"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkUuzJsysrZK"
      },
      "source": [
        "# !python /content/models/research/object_detection/legacy/train.py \\\n",
        "#    --logtostderr \\\n",
        "#    --train_dir={model_dir} \\\n",
        "#    --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdNaoGBSRdDn"
      },
      "source": [
        "# 4. Modell konvertálása és elmentése\n",
        "\n",
        "Amikor már elégedettek vagyunk az eredménnyel, a modellt használható állapotban kell elmenteni. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCRWm5AwuWJv"
      },
      "source": [
        "!rm -rf '/content/fine_tuned_model'"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6PMelYHRzaX"
      },
      "source": [
        "Ez a konfiguráció csak tesztelés jellegel. Az eredeti modellre vonatkozik, így azt a modellt lehet elmenteni, amiből a tanítás kiindult."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSr-ExUXnNih"
      },
      "source": [
        "# output_directory = '/content/fine_tuned_model'\n",
        "# pipeline_fname = '/content/models/research/pretrained_model/pipeline.config.original'\n",
        "# last_model_path = '/content/models/research/pretrained_model/model.ckpt'\n",
        "# saved_model_path = '/content/models/research/pretrained_model/saved_model'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PLQKoUgQGur"
      },
      "source": [
        "Megkeresi a legutolsó tanítási állapotot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7d09a9-9318-47e4-da64-557e6d0ed268"
      },
      "source": [
        "output_directory = '/content/fine_tuned_model'\n",
        "pipeline_fname = '/content/models/research/pretrained_model/pipeline.config'\n",
        "saved_model_path = ''\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnP3_HG9-T6i"
      },
      "source": [
        "pipeline_fname='/content/models/research/pretrained_model/pipeline.config'"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J3RcAECQNnL"
      },
      "source": [
        "A modell exportálása, ezt a fájl tudjuk majd később használni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wE71_gN5RQZ"
      },
      "source": [
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ2hEZ_gQYUA"
      },
      "source": [
        "## Innentől az átalakítás csak opcionális, különböző formátumokbe lehet konvertálni. Bizonyos környezetekben előnyös lehet egyik másik."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLvQB3tqTkcE"
      },
      "source": [
        "### Átalakítás tflife fromátumba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj59rsDz1-nG"
      },
      "source": [
        "!echo \"CONVERTING saved model to TF Lite file...\"\n",
        "!tflite_convert \\\n",
        "  --output_file='{output_directory}/model.tflite' \\\n",
        "  --saved_model_dir='{saved_model_path}' \\\n",
        "  --enable_v1_converter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R6U7Wp7Cpnz"
      },
      "source": [
        "!echo \"CONVERTING saved model to TF Lite file...\"\n",
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "    --pipeline_config_path {pipeline_fname} \\\n",
        "    --trained_checkpoint_prefix {last_model_path} \\\n",
        "    --output_directory {output_directory}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY6kNZwNTrfX"
      },
      "source": [
        "### Átalakítás ONNX fromátumba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzX9P_OdYav1"
      },
      "source": [
        "!pip install tf2onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLU8wNb0YxG0"
      },
      "source": [
        "!python -m tf2onnx.convert \\\n",
        " --saved-model {saved_model_path} \\\n",
        " --output {output_directory}/frozen_inference_graph.onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQM6wXhaG9J8"
      },
      "source": [
        "!python -m tf2onnx.convert \\\n",
        "  --input {frozen_inference_graph} \\\n",
        "  --inputs 'image_tensor:0[1,300,300,3]' \\\n",
        "  --outputs 'detection_boxes:0,detection_scores:0,num_detections:0,detection_classes:0' \\\n",
        "  --opset 11 --fold_const \\\n",
        "  --output {output_directory}/frozen_inference_graph.onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBdz0Z1bHqjG"
      },
      "source": [
        "output_directory = '/content/fine_tuned_model'\n",
        "pipeline_fname = '/content/fine_tuned_model/pipeline.config'\n",
        "last_model_path = '/content/fine_tuned_model/model.ckpt'\n",
        "saved_model_path = '/content/fine_tuned_model/saved_model'\n",
        "frozen_inference_graph = '/content/fine_tuned_model/frozen_inference_graph.pb'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6WbjOFbKqaM"
      },
      "source": [
        "!pip install onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4eBsoPnT1zd"
      },
      "source": [
        "ONNX formátum tesztelése"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtb4sWAaKflC"
      },
      "source": [
        " import onnx\n",
        "\n",
        " # Checks \n",
        " onnx_model = onnx.load('/content/fine_tuned_model/frozen_inference_graph.onnx')  # load onnx model \n",
        " onnx.checker.check_model(onnx_model)  # check onnx model \n",
        " print(onnx.helper.printable_graph(onnx_model.graph))  # print a human readable representation of the graph \n",
        " print('ONNX export success, saved as %s\\nView with https://github.com/lutzroeder/netron' % f) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RdBpi3CUjBg"
      },
      "source": [
        "## Modell letöltése\n",
        "\n",
        "Attól függően milyen formátumba konvertáltuk, különböző fájlokat lehet letölteni. Aalap esetben a következő két fájlra lesz szükség:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP0iMMnnr77"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1TbL6Ox8q6Z"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRr3OtYGWu87"
      },
      "source": [
        "# 5. Használat\n",
        "\n",
        "A használat során újabb képekkel tesztelünk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ5CUFXmUsO6"
      },
      "source": [
        "## Tesztelés TensorFlowval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/content/fine_tuned_model/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "#PATH_TO_TEST_IMAGES_DIR =  '/content/VITMMA10_OD/data/images/test' # os.path.join(repo_dir_path, \"test\")\n",
        "#\n",
        "#assert os.path.isfile(pb_fname)\n",
        "#assert os.path.isfile(PATH_TO_LABELS)\n",
        "#TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg\"))\n",
        "#assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "#print(TEST_IMAGE_PATHS)\n",
        "TEST_IMAGE_PATHS = ['/content/street1z.jpg']\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    print(output_dict)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxjKuLP4U0zc"
      },
      "source": [
        "## Tesztelés OPENCVvel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au-We8Zyt3x3",
        "outputId": "b7ab6500-fe08-4024-9ad2-c6de57277f76"
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nCLWvjKKSaE"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/opencv/opencv.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGj0whnpLB1d"
      },
      "source": [
        "!python /content/opencv/samples/dnn/tf_text_graph_faster_rcnn.py --input {frozen_inference_graph} --config {pipeline_fname} --output /content/opencv.pbtxt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGn2APd7p4hc"
      },
      "source": [
        "# How to load a Tensorflow model using OpenCV\n",
        "# Jean Vitor de Paulo Blog - https://jeanvitor.com/tensorflow-object-detecion-opencv/\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Load a model imported from Tensorflow\n",
        "#tensorflowNet = cv2.dnn.readNetFromTensorflow(pb_fname, label_map_pbtxt_fname)\n",
        "tensorflowNet = cv2.dnn.readNetFromTensorflow('/content/fine_tuned_model/frozen_inference_graph.pb', '/content/opencv.pbtxt' )\n",
        "#tensorflowNet = cv2.dnn.readNetFromONNX('/content/fine_tuned_model/frozen_inference_graph_test.onnx')\n",
        "\n",
        "# Input image\n",
        "img = cv2.imread('/content/VITMMA10_OD/data/images/train/30_1.jpg')\n",
        "rows, cols, channels = img.shape\n",
        "\n",
        "# Use the given image as input, which needs to be blob(s).\n",
        "tensorflowNet.setInput(cv2.dnn.blobFromImage(img, size=(300, 300), swapRB=True, crop=False))\n",
        "\n",
        "# Runs a forward pass to compute the net output\n",
        "networkOutput = tensorflowNet.forward()\n",
        "\n",
        "# Loop on the outputs\n",
        "for detection in networkOutput[0,0]:\n",
        "    \n",
        "    score = float(detection[2])\n",
        "    if score > 0.2:\n",
        "    \t\n",
        "        left = detection[3] * cols\n",
        "        top = detection[4] * rows\n",
        "        right = detection[5] * cols\n",
        "        bottom = detection[6] * rows\n",
        "\n",
        "        #draw a red rectangle around detected objects\n",
        "        cv2.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), (0, 0, 255), thickness=2)\n",
        "\n",
        "# Show the image with a rectagle surrounding the detected objects \n",
        "cv2.imshow('Image', img)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}